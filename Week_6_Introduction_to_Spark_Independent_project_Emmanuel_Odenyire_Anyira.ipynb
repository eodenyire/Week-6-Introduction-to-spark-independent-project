{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Apache Spark DataFrames Project\n",
        "##Project Deliverable\n",
        "You will be required to submit:-\n",
        "###### A GitHub repository with your project written in Pyspark.\n",
        "######Instructions:-\n",
        "*As a Data professional, you need to perform an analysis by answering questions about some stock market data on Safaricom from the years 2012-2017.*\n",
        "######You will need to perform the following:\n",
        "######Data Importation and Exploration\n",
        "\n",
        "\n",
        "> i. Start a spark session and load the stock file while inferring the data types.\n",
        "\n",
        "> ii. Determine the column names\n",
        "\n",
        "> iii. Make observations about the schema.\n",
        "\n",
        ">iv. Show the first 5 rows\n",
        "\n",
        ">v.  Use the describe method to learn about the data frame\n",
        "\n",
        "######Data Preparation\n",
        ">i. Format all the data to 2 decimal places i.e. format_number()\n",
        "\n",
        ">ii. Create a new data frame with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day\n",
        "\n",
        "######Data Analysis\n",
        ">i. What day had the Peak High in Price?\n",
        "\n",
        ">ii. What is the mean of the Close column?\n",
        "\n",
        ">iii. What is the max and min of the Volume column?\n",
        "\n",
        ">iv. How many days was the Close lower than 60 dollars?\n",
        "\n",
        ">v. What percentage of the time was the High greater than 80 dollars?\n",
        "\n",
        ">vi.What is the Pearson correlation between High and Volume?\n",
        "\n",
        ">vii. What is the max High per year?\n",
        "\n",
        ">viii. What is the average Close for each Calendar Month?\n",
        "\n",
        "######Data description\n",
        "● Dataset URL (CSV File): https://bit.ly/3pmchka"
      ],
      "metadata": {
        "id": "vRhIAGvekO5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking validity of the data source by reading the url as a CSV"
      ],
      "metadata": {
        "id": "-GajZ7cGvCdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmsvJA1Sj9Lz",
        "outputId": "ac676c33-30d8-47c6-8bb6-1223e54d0b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date       Open       High        Low      Close    Volume  Adj Close\n",
            "0  2012-01-03  59.970001  61.060001  59.869999  60.330002  12668800  52.619235\n",
            "1  2012-01-04  60.209999  60.349998  59.470001  59.709999   9593300  52.078475\n",
            "2  2012-01-05  59.349998  59.619999  58.369999  59.419998  12768200  51.825539\n",
            "3  2012-01-06  59.419998  59.450001  58.869999  59.000000   8069400  51.459220\n",
            "4  2012-01-09  59.029999  59.549999  58.919998  59.180000   6679300  51.616215\n"
          ]
        }
      ],
      "source": [
        "#To read this CSV into a Python dataframe, you can use the pandas library. \n",
        "#Here's the code to do that:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://bit.ly/3pmchka'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-requisites"
      ],
      "metadata": {
        "id": "zPYQLrERvQMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyspark\n",
        "# ---\n",
        "#\n",
        "!pip install pyspark\n",
        "\n",
        "# Next, we run a local spark session\n",
        "# ---\n",
        "#\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVVngBtZot9X",
        "outputId": "d7603130-6cee-4baf-c674-ee223dce98cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=1ef714482a32ed13fdb73d9ad38f26aaa369e7bcece003ec18f3915400a1034f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Importation and Exploration"
      ],
      "metadata": {
        "id": "FyGaype1w44B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start a spark session and load the stock file while inferring the data types"
      ],
      "metadata": {
        "id": "1nITxN3Ew81A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraries\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "# Start a Spark session\n",
        "spark = SparkSession.builder.appName('SafaricomStockAnalysis').getOrCreate()\n",
        "\n",
        "# Create SQL context object\n",
        "sqlCtx = SQLContext(spark.sparkContext)\n",
        "\n",
        "# Read in the data using the SQL context object\n",
        "df = sqlCtx.read.csv('saf_stock.csv', header=True, inferSchema=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "a7weP7iFouQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the column names\n"
      ],
      "metadata": {
        "id": "6E7dGQtBxC9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X43kwcmqrL7g",
        "outputId": "77b0ec69-ed66-4b90-b71e-4bed45e15fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make observations about the schema.\n"
      ],
      "metadata": {
        "id": "dfiBkcLdxF4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NIdy6OEoucP",
        "outputId": "2df334a6-25b5-49d7-a415-b384619ba359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: timestamp (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "● Show the first 5 rows"
      ],
      "metadata": {
        "id": "uSuFwJN4xPHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWcWJBIbsNAz",
        "outputId": "164ab0b8-0bfe-4666-acfa-0967eb51de89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|               Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03 00:00:00|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04 00:00:00|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05 00:00:00|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06 00:00:00|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09 00:00:00|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the describe method to learn about the data frame"
      ],
      "metadata": {
        "id": "lmDSAEZTxU-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDVGaJpRsNN_",
        "outputId": "4016e33e-05ed-4cc0-e859-31d58944b1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation"
      ],
      "metadata": {
        "id": "R_5tZr01xbme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format all the data to 2 decimal places i.e. format_number()\n"
      ],
      "metadata": {
        "id": "9zkpP510xeOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "High Price versus volume of stock traded for a day"
      ],
      "metadata": {
        "id": "cJAXe5WUxrav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import preparation modules\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import lit,when,col,expr,round\n",
        "\n",
        "# Create a new data frame and round off the columns to two decimal places while adding the new HV column\n",
        "\n",
        "df_prepared=(\n",
        "df.withColumn('HV',expr(\"High/Volume\"))#Create the new column HV which is a ratio if High to Volume ratio of stocks traded\\\n",
        "    .withColumn('Open', F.format_number('Open', 2))# Round the Open Column to two decimal places\\\n",
        "    .withColumn('High', F.format_number('High', 2))# Round the high column to two decimal places\\\n",
        "    .withColumn('Low', F.format_number('Low', 2))# Round the Low column to two decimal places\\\n",
        "    .withColumn('Close', F.format_number('Close', 2))# Round the close column to two decimal places\\\n",
        "    .withColumn('Volume', round('Volume', 2))#round the volume column to two decimal places.Round function used in this case to solve comma issues\\\n",
        "    .withColumn('Adj Close', F.format_number('Adj Close', 2))# Round the close column to two decimal places\\\n",
        "    .withColumn('HV',F.format_number('HV', 10)))# Round the new HV column to 10 decimal places\n",
        " \n",
        "df_prepared.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKrK36CfsNXf",
        "outputId": "97686780-be1d-4976-f14c-2c768f21d0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-----+-----+-----+--------+---------+------------+\n",
            "|               Date| Open| High|  Low|Close|  Volume|Adj Close|          HV|\n",
            "+-------------------+-----+-----+-----+-----+--------+---------+------------+\n",
            "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12668800|    52.62|0.0000048197|\n",
            "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9593300|    52.08|0.0000062908|\n",
            "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12768200|    51.83|0.0000046694|\n",
            "|2012-01-06 00:00:00|59.42|59.45|58.87|59.00| 8069400|    51.46|0.0000073673|\n",
            "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6679300|    51.62|0.0000089156|\n",
            "+-------------------+-----+-----+-----+-----+--------+---------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Analysis"
      ],
      "metadata": {
        "id": "xPdp_ydfnzdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Register a table in SQL\n",
        "table = df_prepared.registerTempTable(\"Data_Analytics\")"
      ],
      "metadata": {
        "id": "Sejv91Amtl-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confirm that SAF has been registered\n",
        "tables = sqlCtx.tableNames()\n",
        "\n",
        "print(tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-b4aQ4xtmKY",
        "outputId": "a528eb95-39ac-471a-fc62-000cb265e1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data_analytics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1: What day had the Peak High in Price?"
      ],
      "metadata": {
        "id": "2JVIUrOvx8Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"SELECT \\\n",
        "         Date,max(High) AS Peak_High_Price \\\n",
        "     FROM Data_Analytics GROUP BY Date \\\n",
        "    ORDER BY Peak_High_Price DESC LIMIT 1 \"\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFUKpkzbtmYX",
        "outputId": "a91c9c98-fca3-4a30-a51b-f444ec4539b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+---------------+\n",
            "|               Date|Peak_High_Price|\n",
            "+-------------------+---------------+\n",
            "|2015-01-13 00:00:00|          90.97|\n",
            "+-------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2: What is the mean of the Close column?\n"
      ],
      "metadata": {
        "id": "UKonEhsyyGZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\\\n",
        "SELECT\\\n",
        "    MEAN(Close) AS MEAN\\\n",
        "        FROM Data_Analytics\"\n",
        "\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WR7SalTuGCR",
        "outputId": "72bcd95f-f5eb-46fc-9bdd-43762fb7c39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|             MEAN|\n",
            "+-----------------+\n",
            "|72.38844992050863|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3:- What is the max and min of the Volume column?\n"
      ],
      "metadata": {
        "id": "1CJhKUN2yNZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"SELECT\\\n",
        "     MIN(Volume) Min_Volume,MAX(Volume) Max_Volume\\\n",
        "         FROM Data_Analytics\\\n",
        " \"\n",
        "\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVHjO3uTuGN3",
        "outputId": "8658464e-fa93-416b-990f-d1cce16595bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Min_Volume|Max_Volume|\n",
            "+----------+----------+\n",
            "|   2094900|  80898100|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4: -How many days was the Close lower than 60 dollars?\n"
      ],
      "metadata": {
        "id": "sBt3LQpkyXgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many days was the close lower than 60 dollars?\n",
        "q = \"SELECT\\\n",
        "    COUNT(Date)\\\n",
        "    FROM Data_Analytics\\\n",
        "    WHERE Close <= 60\\\n",
        "    \"\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8g5oSKfuGTU",
        "outputId": "9681eea9-6233-406e-ffca-ffa491785368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|count(Date)|\n",
            "+-----------+\n",
            "|        116|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5: -What percentage of the time was the High greater than 80 dollars?\n"
      ],
      "metadata": {
        "id": "X63WXMVpyoED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What percentage of the time was the High greater than 80 Dollars\n",
        "# Total column entries were computed earlier. An improved querry of this is to use Common Table Expressions for this querry\n",
        "\n",
        "q = \"SELECT\\\n",
        "     ROUND((COUNT(High)/1258*100),2) Percentage_Greater_Than_80\\\n",
        "         FROM Data_Analytics\\\n",
        "         WHERE High >= 80\\\n",
        "            \"\n",
        "\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGDKe8yHuhoI",
        "outputId": "85c7c98b-a821-46d6-c3cb-fb42a29c0070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|Percentage_Greater_Than_80|\n",
            "+--------------------------+\n",
            "|                      9.14|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6: - What is the Pearson correlation between High and Volume?\n"
      ],
      "metadata": {
        "id": "MhTaOe0UyoSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the Pearson correlation between High and Volume\n",
        "\n",
        "q = \"SELECT ROUND(corr(High,Volume),2) Pearson_Correlation\\\n",
        "          FROM Data_Analytics\"\n",
        "\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3dZusOiuh3P",
        "outputId": "a2325397-8fb5-4eb0-e1c3-97bbda033e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|Pearson_Correlation|\n",
            "+-------------------+\n",
            "|              -0.34|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 7: -What is the max High per year?"
      ],
      "metadata": {
        "id": "39xqOXWiyod6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What is the Max High per Year\n",
        "\n",
        "q = \"SELECT\\\n",
        "     EXTRACT(YEAR FROM Date) Year,\\\n",
        "     MAX(High) Max_High\\\n",
        "     FROM Data_Analytics\\\n",
        "     GROUP BY Year\\\n",
        "     ORDER BY Max_High DESC\"\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGAclJXZuh_w",
        "outputId": "5a6a8909-8022-48cc-a55a-0bd8e8ac41fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+\n",
            "|Year|Max_High|\n",
            "+----+--------+\n",
            "|2015|   90.97|\n",
            "|2014|   88.09|\n",
            "|2013|   81.37|\n",
            "|2012|   77.60|\n",
            "|2016|   75.19|\n",
            "+----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 8: -What is the average Close for each Calendar Month?"
      ],
      "metadata": {
        "id": "XPefdf5Dyyqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What is the average Close for each Calendar Month?\n",
        "q = \"SELECT\\\n",
        "    EXTRACT(MONTH FROM Date) Month,\\\n",
        "    ROUND(AVG(Close),2) Avg_Close\\\n",
        "    FROM Data_Analytics\\\n",
        "    GROUP BY Month\\\n",
        "    ORDER BY Month ASC\"\n",
        "\n",
        "sqlCtx.sql(q).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJBGQnWyuiG3",
        "outputId": "83ec55a6-dd2a-4914-eff6-d7212cd9b86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+\n",
            "|Month|Avg_Close|\n",
            "+-----+---------+\n",
            "|    1|    71.45|\n",
            "|    2|    71.31|\n",
            "|    3|    71.78|\n",
            "|    4|    72.97|\n",
            "|    5|    72.31|\n",
            "|    6|     72.5|\n",
            "|    7|    74.44|\n",
            "|    8|    73.03|\n",
            "|    9|    72.18|\n",
            "|   10|    71.58|\n",
            "|   11|    72.11|\n",
            "|   12|    72.85|\n",
            "+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another approach to achieve this with one complete piece of code"
      ],
      "metadata": {
        "id": "Z-67MnNT0p7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.functions import format_number\n",
        "\n",
        "# Start a Spark session\n",
        "spark = SparkSession.builder.appName('SafaricomStockAnalysis').getOrCreate()\n",
        "\n",
        "# Create SQL context object\n",
        "sqlCtx = SQLContext(spark.sparkContext)\n",
        "\n",
        "# Read in the data using the SQL context object\n",
        "df = sqlCtx.read.csv('saf_stock.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Determine the column names\n",
        "print('Column Names:')\n",
        "for column in df.columns:\n",
        "    print(column)\n",
        "\n",
        "# Make observations about the schema\n",
        "print('Schema:')\n",
        "df.printSchema()\n",
        "\n",
        "# Show the first 5 rows\n",
        "print('First 5 Rows:')\n",
        "df.show(5)\n",
        "\n",
        "# Use the describe method to learn about the data frame\n",
        "print('Dataframe Summary:')\n",
        "df.describe().show()\n",
        "\n",
        "# Format all the data to 2 decimal places\n",
        "\n",
        "df = df.na.fill(0)\n",
        "numeric_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "for col in numeric_cols:\n",
        "    df = df.withColumn(col, df[col].cast('double'))\n",
        "\n",
        "# Create a new data frame with a column called HV Ratio\n",
        "hv_ratio = df.select((df['High'] / df['Volume']).alias('HV Ratio'))\n",
        "\n",
        "# What day had the Peak High in Price?\n",
        "print('Day with Peak High in Price:')\n",
        "df.orderBy(df['High'].desc()).select('Date').head(1)\n",
        "\n",
        "# What is the mean of the Close column?\n",
        "print('Mean of the Close column:')\n",
        "df.select(mean('Close')).show()\n",
        "\n",
        "# What is the max and min of the Volume column?\n",
        "print('Max and Min of the Volume column:')\n",
        "df.select(max('Volume'), min('Volume')).show()\n",
        "\n",
        "# How many days was the Close lower than 60 dollars?\n",
        "print('Days with Close lower than 60 dollars:')\n",
        "df.filter(df['Close'] < 60).count()\n",
        "\n",
        "# What percentage of the time was the High greater than 80 dollars?\n",
        "high_80 = df.filter(df['High'] > 80).count()\n",
        "total_days = df.count()\n",
        "percentage_high_80 = high_80 / total_days * 100\n",
        "print('Percentage of time High was greater than 80 dollars:')\n",
        "print(percentage_high_80)\n",
        "\n",
        "# What is the Pearson correlation between High and Volume?\n",
        "print('Pearson correlation between High and Volume:')\n",
        "df.select(corr('High', 'Volume')).show()\n",
        "\n",
        "# What is the max High per year?\n",
        "max_high = df.select(year('Date').alias('Year'), 'High').groupBy('Year').agg(max('High').alias('Max High'))\n",
        "print('Max High per year:')\n",
        "max_high.show()\n",
        "\n",
        "# What is the average Close for each Calendar Month?\n",
        "avg_close = df.select(month('Date').alias('Month'), 'Close').groupBy('Month').agg(mean('Close').alias('Avg Close'))\n",
        "print('Average Close for each Calendar Month:')\n",
        "avg_close.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXv4sEYFn9Lo",
        "outputId": "c122140b-7238-4262-9cf3-bea327ad5685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names:\n",
            "Date\n",
            "Open\n",
            "High\n",
            "Low\n",
            "Close\n",
            "Volume\n",
            "Adj Close\n",
            "Schema:\n",
            "root\n",
            " |-- Date: timestamp (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n",
            "First 5 Rows:\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|               Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03 00:00:00|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04 00:00:00|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05 00:00:00|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06 00:00:00|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09 00:00:00|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Dataframe Summary:\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n",
            "Day with Peak High in Price:\n",
            "Mean of the Close column:\n",
            "+-----------------+\n",
            "|       avg(Close)|\n",
            "+-----------------+\n",
            "|72.38844998012726|\n",
            "+-----------------+\n",
            "\n",
            "Max and Min of the Volume column:\n",
            "+-----------+-----------+\n",
            "|max(Volume)|min(Volume)|\n",
            "+-----------+-----------+\n",
            "|  8.08981E7|  2094900.0|\n",
            "+-----------+-----------+\n",
            "\n",
            "Days with Close lower than 60 dollars:\n",
            "Percentage of time High was greater than 80 dollars:\n",
            "9.141494435612083\n",
            "Pearson correlation between High and Volume:\n",
            "+-------------------+\n",
            "| corr(High, Volume)|\n",
            "+-------------------+\n",
            "|-0.3384326061737161|\n",
            "+-------------------+\n",
            "\n",
            "Max High per year:\n",
            "+----+---------+\n",
            "|Year| Max High|\n",
            "+----+---------+\n",
            "|2015|90.970001|\n",
            "|2013|81.370003|\n",
            "|2014|88.089996|\n",
            "|2012|77.599998|\n",
            "|2016|75.190002|\n",
            "+----+---------+\n",
            "\n",
            "Average Close for each Calendar Month:\n",
            "+-----+-----------------+\n",
            "|Month|        Avg Close|\n",
            "+-----+-----------------+\n",
            "|   12|72.84792478301885|\n",
            "|    1|71.44801958415842|\n",
            "|    6| 72.4953774245283|\n",
            "|    3|71.77794377570092|\n",
            "|    5|72.30971688679247|\n",
            "|    9|72.18411785294116|\n",
            "|    4|72.97361900952382|\n",
            "|    8|73.02981855454546|\n",
            "|    7|74.43971943925233|\n",
            "|   10|71.57854545454543|\n",
            "|   11| 72.1110893069307|\n",
            "|    2|  71.306804443299|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}